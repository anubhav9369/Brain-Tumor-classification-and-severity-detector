# -*- coding: utf-8 -*-
"""brainTumor_BD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b1ij_Y348vHW80fy_44refte8N_8jyME
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.listdir('/content/drive/MyDrive/brisc2025')

base_dir = '/content/drive/MyDrive/brisc2025'
# Classification folders
classification_train_dir = os.path.join(base_dir, 'classification_task', 'train')
classification_test_dir = os.path.join(base_dir, 'classification_task', 'test')

# Segmentation folders
segmentation_train_dir = os.path.join(base_dir, 'segmentation_task', 'train')
segmentation_test_dir = os.path.join(base_dir, 'segmentation_task', 'test')

"""#Data Preprocessing"""

#Load & Resize Images for Classification
import cv2
import matplotlib.pyplot as plt
import os

sample_path = os.path.join(classification_train_dir, "glioma", os.listdir(os.path.join(classification_train_dir, "glioma"))[0])

# Read image
img = cv2.imread(sample_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Resize to (128,128)
resized_img = cv2.resize(img, (128, 128))

# Show original vs resized
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plt.imshow(img)
plt.title("Original")
plt.axis("off")

plt.subplot(1,2,2)
plt.imshow(resized_img)
plt.title("Resized (128x128)")
plt.axis("off")
plt.show()

#Rescale (Normalize) Pixel Values
import numpy as np

# Normalize image
normalized_img = resized_img.astype(np.float32) / 255.0

print("Before normalization:", resized_img[0,0])   # Pixel RGB values in 0-255
print("After normalization:", normalized_img[0,0]) # Pixel RGB values in 0-1

# Show normalized image
plt.imshow(normalized_img)
plt.title("Normalized Image (0-1 scale)")
plt.axis("off")
plt.show()

#Data Augmentation for Classification
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Augmentation setup
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,          # Zoom in/out by 10%
    horizontal_flip=True,    # Flip images horizontally
    fill_mode='nearest'      # Fill empty pixels after rotation/shift
)

# Prepare single image for augmentation
img = normalized_img
img = np.expand_dims(img, axis=0)  # Shape -> (1, h, w, c)

# Generate and plot 5 augmented images
plt.figure(figsize=(10, 5))
for i, batch in enumerate(datagen.flow(img, batch_size=1)):
    plt.subplot(1, 5, i+1)
    plt.imshow(batch[0])
    plt.axis('off')
    plt.title(f"Aug {i+1}")
    if i == 4:
        break
plt.show()

# Define image_paths and mask_paths based on the segmentation_train_dir structure
image_dir = os.path.join(segmentation_train_dir, 'images')
mask_dir = os.path.join(segmentation_train_dir, 'masks')

# Get list of image and mask file paths
image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]
mask_paths = [os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))]

# You might need to sort these lists to ensure image and mask pairs match
image_paths.sort()
mask_paths.sort()

print(f"Found {len(image_paths)} images and {len(mask_paths)} masks in the training directory.")

#Data Augmentation for Segmentation
!pip install albumentations==1.4.0 --quiet
import albumentations as A
import cv2
import matplotlib.pyplot as plt

# Augmentation pipeline
seg_augment = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=20, p=0.5),
    A.RandomBrightnessContrast(p=0.5)
])

# Pick a random image and mask
img_path = image_paths[0]
mask_path = mask_paths[0]

image = cv2.imread(img_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

# Apply augmentation 5 times
plt.figure(figsize=(10, 5))
for i in range(5):
    augmented = seg_augment(image=image, mask=mask)
    aug_img = augmented['image']
    aug_mask = augmented['mask']

    plt.subplot(2, 5, i+1)
    plt.imshow(aug_img)
    plt.axis('off')
    if i == 0:
        plt.ylabel("Image", fontsize=12)

    plt.subplot(2, 5, i+6)
    plt.imshow(aug_mask, cmap='gray')
    plt.axis('off')
    if i == 0:
        plt.ylabel("Mask", fontsize=12)

plt.suptitle("Segmentation Image & Mask Augmentation", fontsize=14)
plt.show()

"""#ROI and Feature extraction"""

import os
import cv2
import numpy as np
import pandas as pd
from skimage import measure, feature
from skimage.filters import gabor
from scipy import ndimage
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model

def extract_tumor_features(image_path, mask_path, img_size=(128, 128)):

    # Load and preprocess image
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    original_img = img.copy()
    img = cv2.resize(img, img_size)

    # Load and preprocess mask
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    mask = cv2.resize(mask, img_size)
    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)

    # Find contours in the mask
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Initialize features dictionary
    features = {
        'image_path': os.path.basename(image_path),
        'tumor_present': 1 if len(contours) > 0 else 0,
        'num_tumors': len(contours)
    }

    if len(contours) == 0:
        return features

    # Process the largest contour (assumed to be the tumor)
    largest_contour = max(contours, key=cv2.contourArea)

    # Create a mask for the largest tumor
    tumor_mask = np.zeros_like(binary_mask)
    cv2.drawContours(tumor_mask, [largest_contour], -1, 255, thickness=cv2.FILLED)

    # Calculate basic features
    area = cv2.contourArea(largest_contour)
    perimeter = cv2.arcLength(largest_contour, True)

    # Bounding rectangle
    x, y, w, h = cv2.boundingRect(largest_contour)
    aspect_ratio = w / h if h != 0 else 0

    # Convex hull
    hull = cv2.convexHull(largest_contour)
    hull_area = cv2.contourArea(hull)
    solidity = area / hull_area if hull_area != 0 else 0

    # Fit ellipse
    if len(largest_contour) >= 5:
        ellipse = cv2.fitEllipse(largest_contour)
        major_axis = max(ellipse[1])
        minor_axis = min(ellipse[1])
        eccentricity = np.sqrt(1 - (minor_axis/major_axis)**2) if major_axis != 0 else 0
    else:
        major_axis = minor_axis = eccentricity = 0

    # Add geometric features
    features.update({
        'tumor_area': area,
        'tumor_perimeter': perimeter,
        'circularity': (4 * np.pi * area) / (perimeter**2) if perimeter != 0 else 0,
        'aspect_ratio': aspect_ratio,
        'solidity': solidity,
        'major_axis': major_axis,
        'minor_axis': minor_axis,
        'eccentricity': eccentricity
    })

    # Extract intensity features from original image
    original_resized = cv2.resize(original_img, img_size)
    gray_img = cv2.cvtColor(original_resized, cv2.COLOR_RGB2GRAY)

    # Apply tumor mask to get tumor region
    tumor_region = cv2.bitwise_and(gray_img, gray_img, mask=tumor_mask)
    tumor_pixels = tumor_region[tumor_mask > 0]

    if len(tumor_pixels) > 0:
        features.update({
            'mean_intensity': np.mean(tumor_pixels),
            'std_intensity': np.std(tumor_pixels),
            'min_intensity': np.min(tumor_pixels),
            'max_intensity': np.max(tumor_pixels),
            'median_intensity': np.median(tumor_pixels)
        })
    else:
        features.update({
            'mean_intensity': 0,
            'std_intensity': 0,
            'min_intensity': 0,
            'max_intensity': 0,
            'median_intensity': 0
        })

    # Texture features using Gabor filters
    if len(tumor_pixels) > 0:
        gabor_responses = []
        for theta in range(0, 180, 45):
            filtered = gabor(gray_img, frequency=0.1, theta=theta/180.*np.pi)[0]
            tumor_response = filtered[tumor_mask > 0]
            if len(tumor_response) > 0:
                gabor_responses.append(np.mean(tumor_response))

        for i, response in enumerate(gabor_responses):
            features[f'gabor_mean_{i}'] = response
    else:
        for i in range(4):
            features[f'gabor_mean_{i}'] = 0

    return features

# Define paths
segmentation_train_dir = '/content/drive/MyDrive/brisc2025/segmentation_task/train'
image_dir = os.path.join(segmentation_train_dir, 'images')
mask_dir = os.path.join(segmentation_train_dir, 'masks')

# Get list of image and mask file paths
image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]
mask_paths = [os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.jpg') or f.endswith('.png')]

# Sort to ensure matching pairs
image_paths.sort()
mask_paths.sort()

# Verify we have matching pairs
if len(image_paths) != len(mask_paths):
    print("Warning: Number of images and masks don't match!")

# Process all images and extract features
all_features = []
for img_path, mask_path in zip(image_paths, mask_paths):
    try:
        features = extract_tumor_features(img_path, mask_path)
        all_features.append(features)
        print(f"Processed: {os.path.basename(img_path)}")
    except Exception as e:
        print(f"Error processing {img_path}: {str(e)}")

# Convert to DataFrame
features_df = pd.DataFrame(all_features)

# Display the first few rows
print("Extracted Features:")
print(features_df.head())

# Save to CSV
output_csv = 'tumor_features.csv'
features_df.to_csv(output_csv, index=False)
print(f"Features saved to {output_csv}")

from google.colab import files

# Download the CSV file
files.download('tumor_features.csv')

import pandas as pd

# Load the features
features_df = pd.read_csv('tumor_features.csv')

# Display basic information about the dataset
print(f"Dataset shape: {features_df.shape}")
print("\nColumn names:")
print(features_df.columns.tolist())
print("\nFirst few rows:")
print(features_df.head())
print("\nSummary statistics:")
print(features_df.describe())

"""#01-10-2025"""

#Severity labelling
import pandas as pd
import numpy as np
import os
import re
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# Load the segmentation features we extracted earlier
segmentation_features_df = pd.read_csv('tumor_features.csv')

# Define a function to extract image ID from filename
def extract_image_id(filename):
    """Extract the base ID from filename (e.g., brisc2025_train_00001_gl_ax_t1)"""
    # Remove extension and any suffixes
    base_name = os.path.splitext(filename)[0]
    # Extract the ID part (e.g., brisc2025_train_00001)
    match = re.match(r'(brisc2025_[a-z]+_\d+)', base_name)
    if match:
        return match.group(1)
    return base_name

# Add image ID to segmentation features
segmentation_features_df['image_id'] = segmentation_features_df['image_path'].apply(extract_image_id)

# Define a function to determine severity based on tumor characteristics
def determine_severity(row):
    """Determine severity level based on tumor features"""
    if row['tumor_present'] == 0:
        return "No Tumor"

    area = row['tumor_area']
    circularity = row['circularity']
    solidity = row['solidity']

    # Define severity criteria
    if area <= 500 and circularity > 0.7 and solidity > 0.8:
        return "Low"
    elif area <= 1500 and circularity > 0.5 and solidity > 0.7:
        return "Mild"
    else:
        return "High"

# Add proper severity labels to segmentation features
segmentation_features_df['severity'] = segmentation_features_df.apply(determine_severity, axis=1)

# Check severity distribution
print("Severity distribution in segmentation dataset:")
print(segmentation_features_df['severity'].value_counts())

# CLASSIFICATION DATASET PATH SETUP AND IMAGE FILE ORGANIZATION
# Define paths for classification dataset
classification_train_dir = '/content/drive/MyDrive/brisc2025/classification_task/train'

# Get list of image file paths for each class
class_names = ['glioma', 'meningioma', 'no_tumor', 'pituitary']
image_paths_by_class = {}

for class_name in class_names:
    class_dir = os.path.join(classification_train_dir, class_name)
    image_paths = [os.path.join(class_dir, f) for f in os.listdir(class_dir)
                  if f.endswith(('.jpg', '.png'))]
    image_paths_by_class[class_name] = image_paths
    print(f"Found {len(image_paths)} images in {class_name} class")

# Process all images and extract features
all_features = []

for class_name, img_paths in image_paths_by_class.items():
    print(f"\nProcessing {class_name} class...")
    for i, img_path in enumerate(img_paths):
        try:
            # Extract global features
            features = extract_global_features(img_path)

            # Add class label
            features['tumor_type'] = class_name

            # Extract image ID
            image_id = extract_image_id(os.path.basename(img_path))

            # Look up severity from segmentation features
            matching_rows = segmentation_features_df[segmentation_features_df['image_id'] == image_id]

            if len(matching_rows) > 0:
                # Use the severity from segmentation features
                severity = matching_rows.iloc[0]['severity']
            else:
                # If no match, determine based on tumor type
                if class_name == 'no_tumor':
                    severity = "No Tumor"
                elif class_name == 'glioma':
                    # Gliomas are typically more aggressive
                    severity = "High"
                elif class_name == 'meningioma':
                    # Meningiomas are typically less aggressive
                    severity = "Low"
                else:  # pituitary
                    # Pituitary tumors are often benign
                    severity = "Low"

            features['severity'] = severity
            all_features.append(features)

            if (i+1) % 100 == 0:
                print(f"Processed {i+1}/{len(img_paths)} images in {class_name}")
        except Exception as e:
            print(f"Error processing {img_path}: {str(e)}")

# Convert to DataFrame
classification_features_df = pd.DataFrame(all_features)

# Display the first few rows
print("\nExtracted Features for Classification:")
print(classification_features_df.head())

# Check severity distribution
print("\nSeverity distribution:")
print(classification_features_df['severity'].value_counts())

# Save to CSV
output_csv = 'classification_features.csv'
classification_features_df.to_csv(output_csv, index=False)
print(f"\nFeatures saved to {output_csv}")

# Prepare the data
# Drop rows with missing values if any
classification_features_df = classification_features_df.dropna()

# Select feature columns (exclude non-numeric and label columns)
feature_columns = [col for col in classification_features_df.columns
                  if col not in ['image_path', 'tumor_type', 'severity']]
X = classification_features_df[feature_columns]

# Prepare targets
y_type = classification_features_df['tumor_type']
y_severity = classification_features_df['severity']

# Encode tumor type labels
le_type = LabelEncoder()
y_type_encoded = le_type.fit_transform(y_type)

# Encode severity labels
le_severity = LabelEncoder()
y_severity_encoded = le_severity.fit_transform(y_severity)

# Split the data
X_train, X_test, y_type_train, y_type_test, y_severity_train, y_severity_test = train_test_split(
    X, y_type_encoded, y_severity_encoded, test_size=0.2, random_state=42, stratify=y_type_encoded
)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"Training set shape: {X_train_scaled.shape}")
print(f"Testing set shape: {X_test_scaled.shape}")

# Train a model for tumor type classification
print("Training tumor type classifier...")
type_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
type_classifier.fit(X_train_scaled, y_type_train)

# Evaluate tumor type classifier
y_type_pred = type_classifier.predict(X_test_scaled)
print("\nTumor Type Classification Results:")
print(f"Accuracy: {accuracy_score(y_type_test, y_type_pred):.4f}")
print(classification_report(y_type_test, y_type_pred, target_names=le_type.classes_))

# Plot confusion matrix for tumor type
plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_type_test, y_type_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le_type.classes_, yticklabels=le_type.classes_)
plt.title('Confusion Matrix for Tumor Type Classification')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Train a model for severity classification
print("\nTraining severity classifier...")
severity_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
severity_classifier.fit(X_train_scaled, y_severity_train)

# Evaluate severity classifier
y_severity_pred = severity_classifier.predict(X_test_scaled)
print("\nSeverity Classification Results:")
print(f"Accuracy: {accuracy_score(y_severity_test, y_severity_pred):.4f}")
# Convert class labels to strings for the report
severity_class_names = [str(label) for label in le_severity.classes_]
print(classification_report(y_severity_test, y_severity_pred, target_names=severity_class_namesa))

# Plot confusion matrix for severity
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_severity_test, y_severity_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=severity_class_names, yticklabels=severity_class_names)
plt.title('Confusion Matrix for Severity Classification')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Save models and preprocessing objects
joblib.dump(type_classifier, 'tumor_type_classifier.pkl')
joblib.dump(severity_classifier, 'severity_classifier.pkl')
joblib.dump(scaler, 'feature_scaler.pkl')
joblib.dump(le_type, 'label_encoder_type.pkl')
joblib.dump(le_severity, 'label_encoder_severity.pkl')

print("\nModels and preprocessing objects saved successfully!")

from google.colab import files

# List of model files to download
model_files = [
    'tumor_type_classifier.pkl',
    'severity_classifier.pkl',
    'feature_scaler.pkl',
    'label_encoder_type.pkl',
    'label_encoder_severity.pkl'
]

# Download each file
print("Downloading model files for Streamlit app...")
for file in model_files:
    if os.path.exists(file):
        print(f"Downloading {file}...")
        files.download(file)
    else:
        print(f"Warning: {file} not found!")

# Also download the CSV files if needed
csv_files = [
    'tumor_features.csv',
    'classification_features.csv'
]

print("\nDownloading CSV files...")
for file in csv_files:
    if os.path.exists(file):
        print(f"Downloading {file}...")
        files.download(file)
    else:
        print(f"Warning: {file} not found!")

print("\nAll files downloaded successfully!")

# Test with sample images
classification_test_dir = '/content/drive/MyDrive/brisc2025/classification_task/test'

# Test one image from each class
for tumor_class in ['glioma', 'meningioma', 'no_tumor', 'pituitary']:
    class_dir = os.path.join(classification_test_dir, tumor_class)
    if os.path.exists(class_dir) and os.listdir(class_dir):
        test_image_path = os.path.join(class_dir, os.listdir(class_dir)[0])

        if os.path.exists(test_image_path):
            prediction = predict_tumor_characteristics_enhanced(
                test_image_path,
                type_classifier,
                severity_classifier,
                scaler,
                le_type,
                le_severity
            )

            print(f"\n{'='*60}")
            print(f"Analysis for {tumor_class} image:")
            print(f"{'='*60}")
            print(f"Image: {prediction['image_path']}")
            print(f"Tumor Present: {'Yes' if prediction['tumor_present'] else 'No'}")
            print(f"Predicted Tumor Type: {prediction['predicted_tumor_type']}")
            print(f"Predicted Severity: {prediction['predicted_severity']}")
            print(f"\nInterpretation:")
            print(prediction['interpretation'])
            print(f"\nSeverity Details:")
            print(prediction['severity_interpretation'])

!pip install gradio -q

import gradio as gr
import numpy as np
import pandas as pd
import cv2
import os
import joblib
from skimage import feature, filters
from PIL import Image
import time

# Load the trained models and preprocessing objects
print("Loading models...")
type_classifier = joblib.load('/content/tumor_type_classifier (1).pkl')
severity_classifier = joblib.load('/content/severity_classifier (1).pkl')
scaler = joblib.load('/content/feature_scaler (1).pkl')
le_type = joblib.load('/content/label_encoder_type (1).pkl')
le_severity = joblib.load('/content/label_encoder_severity (1).pkl')
print("Models loaded successfully!")

# Define the extract_global_features function (same as used during training)
def extract_global_features(img_path):
    """Extract global features from an image without using a mask"""
    # Read the image
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"Could not read image: {img_path}")

    # Resize to a standard size
    img = cv2.resize(img, (256, 256))

    # Basic statistics
    mean_intensity = np.mean(img)
    std_intensity = np.std(img)
    min_intensity = np.min(img)
    max_intensity = np.max(img)
    median_intensity = np.median(img)

    # Texture features using Local Binary Pattern
    radius = 3
    n_points = 8 * radius
    lbp = feature.local_binary_pattern(img, n_points, radius, method='uniform')
    lbp_hist, _ = np.histogram(lbp.ravel(), bins=n_points + 2, range=(0, n_points + 2))
    lbp_hist = lbp_hist.astype("float")
    lbp_hist /= (lbp_hist.sum() + 1e-7)

    # Edge detection features
    edges = feature.canny(img, sigma=2)
    edge_density = np.sum(edges) / edges.size

    # Gabor filter responses
    gabor_responses = []
    for theta in range(0, 180, 45):
        filtered = filters.gabor(img, frequency=0.1, theta=theta/180.*np.pi)
        gabor_responses.append(np.mean(filtered[0]))

    # Histogram of Oriented Gradients (HOG)
    hog_features = feature.hog(img, orientations=9, pixels_per_cell=(8, 8),
                              cells_per_block=(2, 2), transform_sqrt=True, block_norm='L2-Hys')
    hog_mean = np.mean(hog_features)
    hog_std = np.std(hog_features)

    # Create feature dictionary
    features = {
        'image_path': os.path.basename(img_path),
        'mean_intensity': mean_intensity,
        'std_intensity': std_intensity,
        'min_intensity': min_intensity,
        'max_intensity': max_intensity,
        'median_intensity': median_intensity,
        'edge_density': edge_density,
        'hog_mean': hog_mean,
        'hog_std': hog_std,
    }

    # Add LBP histogram features
    for i, val in enumerate(lbp_hist):
        features[f'lbp_hist_{i}'] = val

    # Add Gabor features
    for i, val in enumerate(gabor_responses):
        features[f'gabor_mean_{i}'] = val

    return features

# Define the prediction function for Gradio
def predict_tumor(image):
    # Save the uploaded image temporarily
    temp_path = "temp_image.jpg"
    cv2.imwrite(temp_path, image)

    try:
        # Extract features
        features = extract_global_features(temp_path)

        # Convert to DataFrame
        features_df = pd.DataFrame([features])

        # Select feature columns (exclude non-numeric and label columns)
        feature_columns = [col for col in features_df.columns
                         if col not in ['image_path', 'tumor_type', 'severity']]
        X = features_df[feature_columns]

        # Scale features
        X_scaled = scaler.transform(X)

        # Predict tumor type
        type_pred_encoded = type_classifier.predict(X_scaled)[0]
        tumor_type = le_type.inverse_transform([type_pred_encoded])[0]

        # Predict severity
        severity_pred_encoded = severity_classifier.predict(X_scaled)[0]
        severity = le_severity.inverse_transform([severity_pred_encoded])[0]

        # Create detailed interpretation
        interpretation = ""
        if tumor_type == "no_tumor":
            interpretation = "No tumor detected in the MRI image."
        elif tumor_type == "glioma":
            interpretation = "Gliomas are tumors that arise from glial cells in the brain. They can vary in aggressiveness."
        elif tumor_type == "meningioma":
            interpretation = "Meningiomas are tumors that develop from the meninges, the membranes surrounding the brain. They are typically slow-growing."
        elif tumor_type == "pituitary":
            interpretation = "Pituitary tumors are abnormal growths that develop in the pituitary gland. They are often benign but can affect hormone production."

        # Add severity-specific interpretation
        if severity == "No Tumor":
            severity_interpretation = "No tumor detected."
        elif severity == "Low":
            severity_interpretation = "Low severity tumor: Small size with well-defined borders. Good prognosis."
        elif severity == "Mild":
            severity_interpretation = "Mild severity tumor: Medium size with some irregularities. Moderate prognosis."
        elif severity == "High":
            severity_interpretation = "High severity tumor: Large size with irregular borders and potential invasion. Requires immediate attention."

        # Prepare the output
        tumor_present = "Yes" if tumor_type != "no_tumor" else "No"

        # Determine colors based on results
        if tumor_type == "no_tumor":
            tumor_color = "#28a745"  # Green
            tumor_icon = "‚úì"
        else:
            tumor_color = "#dc3545"  # Red
            tumor_icon = "‚ö†Ô∏è"

        if severity == "No Tumor":
            severity_color = "#28a745"  # Green
            severity_icon = "‚úì"
        elif severity == "Low":
            severity_color = "#ffc107"  # Yellow
            severity_icon = "‚ö†Ô∏è"
        elif severity == "Mild":
            severity_color = "#fd7e14"  # Orange
            severity_icon = "‚ö†Ô∏è"
        else:  # High
            severity_color = "#dc3545"  # Red
            severity_icon = "‚ö†Ô∏è"

        # Format the results with enhanced styling
        result = f"""
        <div style="font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; max-width: 600px; margin: 0 auto;">
            <div style="background: linear-gradient(135deg, #6a11cb 0%, #2575fc 100%); color: white; padding: 20px; border-radius: 15px 15px 0 0; text-align: center; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                <h1 style="margin: 0; font-size: 28px; font-weight: 600;">Brain Tumor Analysis Results</h1>
                <p style="margin: 10px 0 0 0; opacity: 0.9;">AI-Powered Medical Imaging Analysis</p>
            </div>

            <div style="background-color: #ffffff; padding: 25px; border-radius: 0 0 15px 15px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
                <div style="text-align: center; margin-bottom: 25px;">
                    <div style="display: inline-block; padding: 12px 25px; background-color: #f8f9fa; border-radius: 30px; font-size: 18px; font-weight: 600; color: #495057;">
                        Tumor Present: <span style="color: {tumor_color}; font-weight: 700;">{tumor_present}</span>
                    </div>
                </div>

                <div style="margin-bottom: 25px;">
                    <div style="display: flex; align-items: center; margin-bottom: 15px;">
                        <div style="font-size: 32px; margin-right: 15px;">{tumor_icon}</div>
                        <div style="flex: 1;">
                            <div style="font-size: 16px; color: #6c757d; margin-bottom: 3px;">Predicted Tumor Type</div>
                            <div style="font-size: 24px; font-weight: 700; color: {tumor_color};">{tumor_type}</div>
                        </div>
                    </div>

                    <div style="background-color: #f8f9fa; padding: 18px; border-radius: 10px; border-left: 4px solid {tumor_color};">
                        <div style="font-size: 15px; color: #495057; line-height: 1.6; font-weight: 500;">{interpretation}</div>
                    </div>
                </div>

                <div>
                    <div style="display: flex; align-items: center; margin-bottom: 15px;">
                        <div style="font-size: 32px; margin-right: 15px;">{severity_icon}</div>
                        <div style="flex: 1;">
                            <div style="font-size: 16px; color: #6c757d; margin-bottom: 3px;">Predicted Severity</div>
                            <div style="font-size: 24px; font-weight: 700; color: {severity_color};">{severity}</div>
                        </div>
                    </div>

                    <div style="background-color: #f8f9fa; padding: 18px; border-radius: 10px; border-left: 4px solid {severity_color};">
                        <div style="font-size: 15px; color: #495057; line-height: 1.6; font-weight: 500;">{severity_interpretation}</div>
                    </div>
                </div>

                <div style="margin-top: 30px; padding-top: 20px; border-top: 1px solid #e9ecef; text-align: center;">
                    <div style="display: inline-block; padding: 8px 16px; background-color: #f8f9fa; border-radius: 20px; color: #6c757d; font-size: 14px; margin-bottom: 10px;">
                        <span style="font-weight: 600;">Disclaimer:</span> For demonstration purposes only
                    </div>
                    <p style="margin: 0; color: #6c757d; font-size: 14px;">
                        This system should not be used for actual medical diagnosis. Always consult with a qualified healthcare professional.
                    </p>
                </div>
            </div>
        </div>
        """

        return result

    except Exception as e:
        return f"""
        <div style="font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; max-width: 600px; margin: 0 auto; background-color: #f8d7da; color: #721c24; padding: 20px; border-radius: 10px; text-align: center;">
            <h2 style="margin-top: 0;">Error</h2>
            <p>{str(e)}</p>
        </div>
        """
    finally:
        # Clean up temporary file
        if os.path.exists(temp_path):
            os.remove(temp_path)

# Create the Gradio interface
with gr.Blocks(title="Brain Tumor Classification System", theme=gr.themes.Soft(primary_hue="indigo")) as demo:
    gr.Markdown(
        """
        # <div style="text-align: center;">üß† Brain Tumor Classification System</div>

        <div style="text-align: center; font-size: 18px; color: #6c757d; margin-bottom: 20px;">
        Upload an MRI image to classify the tumor type and severity using AI technology.
        </div>
        """
    )

    with gr.Row():
        with gr.Column(scale=1):
            image_input = gr.Image(
                label="Upload MRI Image",
                type="numpy",
                elem_id="image-input"
            )
            submit_btn = gr.Button(
                "Analyze Image",
                variant="primary",
                size="lg",
                elem_id="analyze-btn"
            )

        with gr.Column(scale=1):
            result_output = gr.HTML(
                label="Analysis Results",
                elem_id="results-output"
            )

    # Example images
    gr.Examples(
        examples=[
            ["/content/brisc2025_test_00001_gl_ax_t1.jpg"],
            ["/content/brisc2025_test_00257_me_ax_t1.jpg"],
            ["/content/brisc2025_test_00569_no_ax_t1.jpg"],
            ["/content/brisc2025_test_00712_pi_ax_t1.jpg"]
        ],
        inputs=image_input,
        label="Example Images",
        examples_per_page=4
    )

    # Set up the click event
    submit_btn.click(
        fn=predict_tumor,
        inputs=image_input,
        outputs=result_output
    )

    gr.Markdown(
        """
        ### How It Works:
        1. Upload an MRI image of the brain
        2. The system extracts features from the image
        3. Machine learning models predict tumor type and severity
        4. Results are displayed with detailed interpretations

        ### Note:
        This system is for demonstration purposes only and should not be used for actual medical diagnosis.
        """
    )

# Custom CSS for better styling
demo.css = """
#image-input {
    border-radius: 10px;
    border: 2px dashed #6a11cb;
}
#analyze-btn {
    background: linear-gradient(135deg, #6a11cb 0%, #2575fc 100%);
    color: white;
    font-weight: 600;
    border-radius: 8px;
    padding: 12px 20px;
}
#analyze-btn:hover {
    background: linear-gradient(135deg, #5a0dbb 0%, #1565eb 100%);
}
#results-output {
    border-radius: 10px;
    overflow: hidden;
}
"""

# Launch the interface
demo.launch(share=True)

